# Coolify/Docker environment variables

# Port configuration
PORT=7860

# GPU Configuration
CUDA_VISIBLE_DEVICES=0

# Hugging Face (optional - for private models)
# HUGGING_FACE_HUB_TOKEN=your_token_here

# Model cache directory (inside container)
HF_HOME=/app/models
TRANSFORMERS_CACHE=/app/models
TORCH_HOME=/app/models/torch

# Performance settings
SPCONV_ALGO=native
ATTN_BACKEND=xformers

# Gradio settings
GRADIO_SERVER_NAME=0.0.0.0
GRADIO_SERVER_PORT=7860
GRADIO_ANALYTICS_ENABLED=false

# Memory settings (adjust based on your GPU)
# For A100 40GB: 24G limit, 16G reservation
# For RTX 3090 24GB: 20G limit, 16G reservation
# For RTX 4090 24GB: 20G limit, 16G reservation
MEMORY_LIMIT=24G
MEMORY_RESERVATION=16G 